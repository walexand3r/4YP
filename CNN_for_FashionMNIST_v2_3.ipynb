{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "name": "CNN_for_FashionMNIST_v2.3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walexand3r/4YP/blob/master/CNN_for_FashionMNIST_v2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgeRXODCpXnN",
        "colab_type": "text"
      },
      "source": [
        "Model Version 2.3\n",
        "\n",
        "Simple sequential Keras Model for use on Fashion MNIST dataset\n",
        "\n",
        "Carries out four tests\n",
        "\n",
        "Added: \n",
        " - Merged training and prediction steps\n",
        " - Duplicated entire process for each test combination\n",
        "\n",
        "To Add:\n",
        " - Turn Test blocks into a function, for now, works fine as all blocks run sequentially\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcOpH2s7jxyl",
        "colab_type": "code",
        "outputId": "551cdc3a-8c18-4bdb-be51-9302099a1ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "\n",
        "# This block imports relevant packages and sets intial seed to ensure reproducability\n",
        "# Seed value\n",
        "seed_value= 0\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os, datetime\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(seed_value)\n",
        "# for later versions: tf.random.set_random_seed(seed_value)\n",
        "\n",
        "# 5. Configure a new global `tensorflow` session\n",
        "import tensorflow.keras as keras\n",
        "# from tensorflow.keras import backend as K\n",
        "# session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "# sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "# K.set_session(sess)\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "%load_ext tensorboard\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y2LCs4A2Bwvu",
        "outputId": "e535fe72-d984-4f2a-80ff-948bc870dd54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "6fd06778-40a8-40cb-e9ea-c59e5795e78c",
        "colab_type": "code",
        "id": "7hNI5LLvrTqR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fi4vIFCUB9J2",
        "colab": {}
      },
      "source": [
        "num_classes = 10    \n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "# Build and compile model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(learning_rate = 1),\n",
        "              metrics=['accuracy'])\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zuFOTq9KixG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sets paths for train/test D/D+\n",
        "folder = 'Intensity Scaled'\n",
        "path = '/content/drive/My Drive/4th Year/4YP/Fashion MNIST 60k/Processed Datasets/'\n",
        "pathDtrain  = path[:74] + folder  + '/D_train.csv'\n",
        "pathDplustrain  = path[:74] + folder  + '/D+_train.csv'\n",
        "pathDtest  = path[:74] + folder  + '/D_test.csv'\n",
        "pathDplustest  = path[:74] + folder  + '/D+_test.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kW1Lgod8B9W3",
        "outputId": "212cc691-63e8-4dfc-b3a3-662b99f65cb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Test 1: R(M,D)     \n",
        "# Full data import, learning and test of: D_train and D_test\n",
        "# loading modified Fashion MNIST dataset\n",
        "train = pd.read_csv(pathDtrain,header=None)\n",
        "test = pd.read_csv(pathDtest,header=None)\n",
        "(n_train,pixels) = np.shape(train)\n",
        "n_test = np.size(test,0)\n",
        "dim = int(np.sqrt(pixels-1))\n",
        "\n",
        "# Getting data in right form\n",
        "# input image dimensions\n",
        "img_rows, img_cols = dim, dim\n",
        "\n",
        "# Extracting data\n",
        "test_labels = test.iloc[:,0]\n",
        "test_values = test.iloc[:,1:]\n",
        "train_labels = train.iloc[:,0]\n",
        "train_values = train.iloc[:,1:]\n",
        "x_train = train_values.values.reshape(n_train,img_rows,img_cols,1)\n",
        "x_test = test_values.values.reshape(n_test,img_rows,img_cols,1)\n",
        "\n",
        "# print('x_train shape:', x_train.shape)\n",
        "# print(x_train.shape[0], 'train samples')\n",
        "# print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(train_labels, num_classes)\n",
        "y_test = keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Fit model and learn\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[tensorboard_callback])\n",
        "\n",
        "# Make predictions\n",
        "predictions_1 = model.predict(x_test, batch_size=batch_size,\n",
        "                            verbose=1,)\n",
        "# Forming into required raw data format\n",
        "predictions_1 = predictions_1.round(0)\n",
        "MLresults_1 = np.argmax(predictions_1,axis=1)\n",
        "\n",
        "Correctness_1 = np.zeros(len(predictions_1))\n",
        "for i in range(len(predictions_1)):\n",
        "  if np.array_equal(MLresults_1[i],test_labels[i]):\n",
        "    Correctness_1[i] = True\n",
        "  else:\n",
        "    Correctness_1[i] = False\n",
        "\n",
        "GroundTruth_1 = test_labels\n",
        "\n",
        "RawData_1 = np.zeros((n_test,5))\n",
        "RawData_1[:,1] = GroundTruth_1\n",
        "RawData_1[:,2] = MLresults_1\n",
        "RawData_1[:,4] = Correctness_1\n",
        "\n",
        "for i in range(len(GroundTruth_1)):\n",
        "  RawData_1[i,0] = i+1\n",
        "\n",
        "# Saving\n",
        "savePath = '/content/drive/My Drive/4th Year/4YP/Fashion MNIST 60k/Results/' + folder + '/R(M,D).csv'\n",
        "#pd.DataFrame(RawData_1).to_csv(savePath,header=None, index=None)\n",
        "\n",
        "# # Testing accuracy for interest\n",
        "# sum(Correctness_1) / 10000\n",
        "# #y_test = y_test.astype(np.float32)\n",
        "# score = model.evaluate(x_test, y_test, verbose=0)\n",
        "# print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 5s 89us/sample - loss: 2.2780 - accuracy: 0.5596 - val_loss: 0.4938 - val_accuracy: 0.8124\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.5275 - accuracy: 0.8110 - val_loss: 0.4252 - val_accuracy: 0.8403\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4520 - accuracy: 0.8370 - val_loss: 0.3884 - val_accuracy: 0.8583\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4185 - accuracy: 0.8503 - val_loss: 0.3695 - val_accuracy: 0.8610\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3941 - accuracy: 0.8579 - val_loss: 0.3340 - val_accuracy: 0.8723\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3741 - accuracy: 0.8659 - val_loss: 0.3263 - val_accuracy: 0.8794\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3632 - accuracy: 0.8675 - val_loss: 0.3264 - val_accuracy: 0.8827\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3475 - accuracy: 0.8739 - val_loss: 0.3448 - val_accuracy: 0.8820\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3402 - accuracy: 0.8761 - val_loss: 0.3355 - val_accuracy: 0.8704\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3305 - accuracy: 0.8821 - val_loss: 0.3064 - val_accuracy: 0.8830\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3265 - accuracy: 0.8822 - val_loss: 0.3019 - val_accuracy: 0.8917\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3175 - accuracy: 0.8858 - val_loss: 0.3075 - val_accuracy: 0.8855\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3075 - accuracy: 0.8891 - val_loss: 0.3160 - val_accuracy: 0.8848\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3012 - accuracy: 0.8911 - val_loss: 0.3125 - val_accuracy: 0.8893\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2994 - accuracy: 0.8931 - val_loss: 0.3307 - val_accuracy: 0.8811\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2956 - accuracy: 0.8949 - val_loss: 0.3029 - val_accuracy: 0.8943\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2842 - accuracy: 0.8986 - val_loss: 0.3077 - val_accuracy: 0.8896\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2778 - accuracy: 0.9000 - val_loss: 0.3590 - val_accuracy: 0.8810\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2717 - accuracy: 0.9024 - val_loss: 0.2927 - val_accuracy: 0.8935\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2703 - accuracy: 0.9032 - val_loss: 0.3180 - val_accuracy: 0.8896\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2642 - accuracy: 0.9060 - val_loss: 0.3143 - val_accuracy: 0.8852\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2597 - accuracy: 0.9070 - val_loss: 0.3227 - val_accuracy: 0.8853\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2562 - accuracy: 0.9099 - val_loss: 0.3089 - val_accuracy: 0.8912\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 5s 87us/sample - loss: 0.2513 - accuracy: 0.9134 - val_loss: 0.3156 - val_accuracy: 0.8894\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2479 - accuracy: 0.9125 - val_loss: 0.3766 - val_accuracy: 0.8928\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2478 - accuracy: 0.9135 - val_loss: 0.3607 - val_accuracy: 0.8948\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2418 - accuracy: 0.9148 - val_loss: 0.3512 - val_accuracy: 0.8942\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2346 - accuracy: 0.9170 - val_loss: 0.3214 - val_accuracy: 0.8925\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2335 - accuracy: 0.9195 - val_loss: 0.3404 - val_accuracy: 0.8963\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2343 - accuracy: 0.9190 - val_loss: 0.3352 - val_accuracy: 0.8926\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2266 - accuracy: 0.9207 - val_loss: 0.3420 - val_accuracy: 0.8887\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2251 - accuracy: 0.9220 - val_loss: 0.3733 - val_accuracy: 0.8865\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2240 - accuracy: 0.9229 - val_loss: 0.4435 - val_accuracy: 0.8910\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2143 - accuracy: 0.9260 - val_loss: 0.3807 - val_accuracy: 0.8969\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2235 - accuracy: 0.9243 - val_loss: 0.3363 - val_accuracy: 0.8927\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2112 - accuracy: 0.9270 - val_loss: 0.4322 - val_accuracy: 0.8912\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2145 - accuracy: 0.9280 - val_loss: 0.3456 - val_accuracy: 0.8918\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2132 - accuracy: 0.9276 - val_loss: 0.3437 - val_accuracy: 0.8859\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2012 - accuracy: 0.9316 - val_loss: 0.3280 - val_accuracy: 0.8906\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2013 - accuracy: 0.9304 - val_loss: 0.4922 - val_accuracy: 0.8912\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2051 - accuracy: 0.9296 - val_loss: 0.3521 - val_accuracy: 0.8883\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2015 - accuracy: 0.9307 - val_loss: 0.4341 - val_accuracy: 0.8831\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2005 - accuracy: 0.9322 - val_loss: 0.4086 - val_accuracy: 0.8888\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1960 - accuracy: 0.9338 - val_loss: 0.4156 - val_accuracy: 0.8934\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1993 - accuracy: 0.9339 - val_loss: 0.4526 - val_accuracy: 0.8903\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1927 - accuracy: 0.9347 - val_loss: 0.3646 - val_accuracy: 0.8912\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1981 - accuracy: 0.9327 - val_loss: 0.3999 - val_accuracy: 0.8918\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1907 - accuracy: 0.9360 - val_loss: 0.4304 - val_accuracy: 0.8947\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1890 - accuracy: 0.9369 - val_loss: 0.3814 - val_accuracy: 0.8868\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1913 - accuracy: 0.9365 - val_loss: 0.5324 - val_accuracy: 0.8947\n",
            "10000/10000 [==============================] - 0s 27us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVlJRe2iMFGl",
        "colab_type": "code",
        "outputId": "65e30940-a9b0-401f-d39e-4400d7d1a7c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "savePath = '/content/drive/My Drive/4th Year/4YP/Fashion MNIST 60k/Results/' + folder + '/R(M,D).csv'\n",
        "#pd.DataFrame(RawData_1).to_csv(savePath,header=None, index=None)\n",
        "print('R(M,D+):',(sum(Correctness_1) / 10000))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R(M,D+): 0.8934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FgBormz_rJxj",
        "outputId": "32e36f2c-cda0-4a5a-89a4-ac4c258345db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Test 2: R(M+,D)\n",
        "# Full data import, learning and test of: D_train and D_test\n",
        "# loading modified Fashion MNIST dataset\n",
        "train = pd.read_csv(pathDplustrain,header=None)\n",
        "test = pd.read_csv(pathDtest,header=None)\n",
        "(n_train,pixels) = np.shape(train)\n",
        "n_test = np.size(test,0)\n",
        "dim = int(np.sqrt(pixels-1))\n",
        "\n",
        "# Getting data in right form\n",
        "# input image dimensions\n",
        "img_rows, img_cols = dim, dim\n",
        "\n",
        "# Extracting data\n",
        "test_labels = test.iloc[:,0]\n",
        "test_values = test.iloc[:,1:]\n",
        "train_labels = train.iloc[:,0]\n",
        "train_values = train.iloc[:,1:]\n",
        "x_train = train_values.values.reshape(n_train,img_rows,img_cols,1)\n",
        "x_test = test_values.values.reshape(n_test,img_rows,img_cols,1)\n",
        "\n",
        "# print('x_train shape:', x_train.shape)\n",
        "# print(x_train.shape[0], 'train samples')\n",
        "# print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(train_labels, num_classes)\n",
        "y_test = keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Fit model and learn\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[tensorboard_callback])\n",
        "\n",
        "# Make predictions\n",
        "predictions_2 = model.predict(x_test, batch_size=batch_size,\n",
        "                            verbose=1,)\n",
        "# Forming into required raw data format\n",
        "predictions_2 = predictions_2.round(0)\n",
        "MLresults_2 = np.argmax(predictions_2,axis=1)\n",
        "\n",
        "Correctness_2 = np.zeros(len(predictions_2))\n",
        "for i in range(len(predictions_2)):\n",
        "  if np.array_equal(MLresults_2[i],test_labels[i]):\n",
        "    Correctness_2[i] = True\n",
        "  else:\n",
        "    Correctness_2[i] = False\n",
        "\n",
        "GroundTruth_2 = test_labels\n",
        "\n",
        "RawData_2 = np.zeros((n_test,5))\n",
        "RawData_2[:,1] = GroundTruth_2\n",
        "RawData_2[:,2] = MLresults_2\n",
        "RawData_2[:,4] = Correctness_2\n",
        "\n",
        "for i in range(len(GroundTruth_2)):\n",
        "  RawData_2[i,0] = i+1\n",
        "\n",
        "# Saving\n",
        "savePath = '/content/drive/My Drive/4th Year/4YP/Fashion MNIST 60k/Results/' + folder + '/R(M+,D).csv'\n",
        "#pd.DataFrame(RawData_2).to_csv(savePath,header=None, index=None)\n",
        "\n",
        "# # Testing accuracy for interest\n",
        "# sum(Correctness_2) / 10000\n",
        "# #y_test = y_test.astype(np.float32)\n",
        "# score = model.evaluate(x_test, y_test, verbose=0)\n",
        "# print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 1.8289 - accuracy: 0.6650 - val_loss: 1.1503 - val_accuracy: 0.6182\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.5149 - accuracy: 0.8158 - val_loss: 1.3278 - val_accuracy: 0.5972\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4538 - accuracy: 0.8370 - val_loss: 2.2438 - val_accuracy: 0.5165\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4145 - accuracy: 0.8527 - val_loss: 1.2415 - val_accuracy: 0.6378\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3936 - accuracy: 0.8587 - val_loss: 1.0059 - val_accuracy: 0.6684\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3745 - accuracy: 0.8653 - val_loss: 1.1048 - val_accuracy: 0.6250\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.3565 - accuracy: 0.8705 - val_loss: 1.3817 - val_accuracy: 0.5867\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3499 - accuracy: 0.8737 - val_loss: 1.1968 - val_accuracy: 0.6315\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3418 - accuracy: 0.8772 - val_loss: 1.3919 - val_accuracy: 0.6259\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3346 - accuracy: 0.8784 - val_loss: 1.3707 - val_accuracy: 0.6049\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3253 - accuracy: 0.8845 - val_loss: 1.2447 - val_accuracy: 0.6607\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3234 - accuracy: 0.8848 - val_loss: 1.5896 - val_accuracy: 0.6176\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3133 - accuracy: 0.8870 - val_loss: 2.2355 - val_accuracy: 0.5368\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3086 - accuracy: 0.8893 - val_loss: 1.5461 - val_accuracy: 0.6034\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2995 - accuracy: 0.8916 - val_loss: 1.8923 - val_accuracy: 0.6062\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2969 - accuracy: 0.8942 - val_loss: 1.4306 - val_accuracy: 0.6464\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2901 - accuracy: 0.8957 - val_loss: 2.1312 - val_accuracy: 0.5749\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2862 - accuracy: 0.8978 - val_loss: 1.4750 - val_accuracy: 0.6310\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2814 - accuracy: 0.8988 - val_loss: 1.7242 - val_accuracy: 0.6208\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.2808 - accuracy: 0.8996 - val_loss: 2.4495 - val_accuracy: 0.5434\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2775 - accuracy: 0.9014 - val_loss: 1.9423 - val_accuracy: 0.6173\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2724 - accuracy: 0.9021 - val_loss: 3.7937 - val_accuracy: 0.5287\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2719 - accuracy: 0.9040 - val_loss: 3.9699 - val_accuracy: 0.5478\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2673 - accuracy: 0.9052 - val_loss: 2.9003 - val_accuracy: 0.5476\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2599 - accuracy: 0.9071 - val_loss: 2.5876 - val_accuracy: 0.5949\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2587 - accuracy: 0.9076 - val_loss: 3.0637 - val_accuracy: 0.5927\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2563 - accuracy: 0.9089 - val_loss: 3.6461 - val_accuracy: 0.5575\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2575 - accuracy: 0.9092 - val_loss: 5.4806 - val_accuracy: 0.5106\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2498 - accuracy: 0.9112 - val_loss: 3.9267 - val_accuracy: 0.5372\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2509 - accuracy: 0.9128 - val_loss: 3.3690 - val_accuracy: 0.5894\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2491 - accuracy: 0.9125 - val_loss: 3.1347 - val_accuracy: 0.6100\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2491 - accuracy: 0.9135 - val_loss: 3.2617 - val_accuracy: 0.5993\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2466 - accuracy: 0.9141 - val_loss: 4.2854 - val_accuracy: 0.5712\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2432 - accuracy: 0.9157 - val_loss: 3.8089 - val_accuracy: 0.5590\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2449 - accuracy: 0.9149 - val_loss: 4.2480 - val_accuracy: 0.5399\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2357 - accuracy: 0.9173 - val_loss: 5.3574 - val_accuracy: 0.5443\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2350 - accuracy: 0.9185 - val_loss: 3.8251 - val_accuracy: 0.5875\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2344 - accuracy: 0.9194 - val_loss: 2.6264 - val_accuracy: 0.6170\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2334 - accuracy: 0.9187 - val_loss: 3.6054 - val_accuracy: 0.5986\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2355 - accuracy: 0.9183 - val_loss: 3.9940 - val_accuracy: 0.6056\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2352 - accuracy: 0.9194 - val_loss: 3.4036 - val_accuracy: 0.5862\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2281 - accuracy: 0.9203 - val_loss: 5.0290 - val_accuracy: 0.5701\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2287 - accuracy: 0.9220 - val_loss: 5.8981 - val_accuracy: 0.5420\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2268 - accuracy: 0.9223 - val_loss: 5.2623 - val_accuracy: 0.5459\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2277 - accuracy: 0.9225 - val_loss: 4.9759 - val_accuracy: 0.5788\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2274 - accuracy: 0.9225 - val_loss: 4.6785 - val_accuracy: 0.5834\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2280 - accuracy: 0.9232 - val_loss: 6.0518 - val_accuracy: 0.5532\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2238 - accuracy: 0.9228 - val_loss: 4.1912 - val_accuracy: 0.5940\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2249 - accuracy: 0.9243 - val_loss: 5.1192 - val_accuracy: 0.5746\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2223 - accuracy: 0.9241 - val_loss: 7.9361 - val_accuracy: 0.5277\n",
            "10000/10000 [==============================] - 0s 29us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj7awRbCIJEp",
        "colab_type": "code",
        "outputId": "2232196e-5fcc-49a8-c42f-0af062db6971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "savePath = '/content/drive/My Drive/4th Year/4YP/Fashion MNIST 60k/Results/' + folder + '/R(M+,D).csv'\n",
        "#pd.DataFrame(RawData_2).to_csv(savePath,header=None, index=None)\n",
        "print('R(M,D+):',(sum(Correctness_2) / 10000))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R(M,D+): 0.5243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dr_7AVL-s8sS",
        "outputId": "a7f50c91-6c47-4e9d-b656-90877ceaaa31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Test 3: R(M,D+)\n",
        "# Full data import, learning and test of: D_train and D_test\n",
        "# loading modified Fashion MNIST dataset\n",
        "train = pd.read_csv(pathDtrain,header=None)\n",
        "test = pd.read_csv(pathDplustest,header=None)\n",
        "(n_train,pixels) = np.shape(train)\n",
        "n_test = np.size(test,0)\n",
        "dim = int(np.sqrt(pixels-1))\n",
        "\n",
        "# Getting data in right form\n",
        "# input image dimensions\n",
        "img_rows, img_cols = dim, dim\n",
        "\n",
        "# Extracting data\n",
        "test_labels = test.iloc[:,0]\n",
        "test_values = test.iloc[:,1:]\n",
        "train_labels = train.iloc[:,0]\n",
        "train_values = train.iloc[:,1:]\n",
        "x_train = train_values.values.reshape(n_train,img_rows,img_cols,1)\n",
        "x_test = test_values.values.reshape(n_test,img_rows,img_cols,1)\n",
        "\n",
        "# print('x_train shape:', x_train.shape)\n",
        "# print(x_train.shape[0], 'train samples')\n",
        "# print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(train_labels, num_classes)\n",
        "y_test = keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Fit model and learn\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[tensorboard_callback])\n",
        "\n",
        "# Make predictions\n",
        "predictions_3 = model.predict(x_test, batch_size=batch_size,\n",
        "                            verbose=1,)\n",
        "# Forming into required raw data format\n",
        "predictions_3 = predictions_3.round(0)\n",
        "MLresults_3 = np.argmax(predictions_3,axis=1)\n",
        "\n",
        "Correctness_3 = np.zeros(len(predictions_3))\n",
        "for i in range(len(predictions_3)):\n",
        "  if np.array_equal(MLresults_3[i],test_labels[i]):\n",
        "    Correctness_3[i] = True\n",
        "  else:\n",
        "    Correctness_3[i] = False\n",
        "\n",
        "GroundTruth_3 = test_labels\n",
        "\n",
        "RawData_3 = np.zeros((n_test,5))\n",
        "RawData_3[:,1] = GroundTruth_3\n",
        "RawData_3[:,2] = MLresults_3\n",
        "RawData_3[:,4] = Correctness_3\n",
        "\n",
        "for i in range(len(GroundTruth_3)):\n",
        "  RawData_3[i,0] = i+1\n",
        "\n",
        "# Saving\n",
        "savePath = '/content/drive/My Drive/4th Year/4YP/Fashion MNIST 60k/Results/' + folder + '/R(M,D+).csv'\n",
        "#pd.DataFrame(RawData_3).to_csv(savePath,header=None, index=None)\n",
        "\n",
        "# # Testing accuracy for interest\n",
        "# sum(Correctness_3) / 10000\n",
        "# #y_test = y_test.astype(np.float32)\n",
        "# score = model.evaluate(x_test, y_test, verbose=0)\n",
        "# print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 2.1951 - accuracy: 0.4722 - val_loss: 0.5124 - val_accuracy: 0.8131\n",
            "Epoch 2/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.5438 - accuracy: 0.8019 - val_loss: 0.4087 - val_accuracy: 0.8544\n",
            "Epoch 3/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4674 - accuracy: 0.8318 - val_loss: 0.3772 - val_accuracy: 0.8622\n",
            "Epoch 4/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4242 - accuracy: 0.8468 - val_loss: 0.3428 - val_accuracy: 0.8723\n",
            "Epoch 5/40\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3950 - accuracy: 0.8557 - val_loss: 0.3449 - val_accuracy: 0.8768\n",
            "Epoch 6/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3745 - accuracy: 0.8662 - val_loss: 0.3415 - val_accuracy: 0.8754\n",
            "Epoch 7/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3634 - accuracy: 0.8683 - val_loss: 0.3271 - val_accuracy: 0.8796\n",
            "Epoch 8/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3487 - accuracy: 0.8739 - val_loss: 0.3219 - val_accuracy: 0.8863\n",
            "Epoch 9/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3404 - accuracy: 0.8774 - val_loss: 0.4229 - val_accuracy: 0.8725\n",
            "Epoch 10/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3304 - accuracy: 0.8827 - val_loss: 0.3425 - val_accuracy: 0.8902\n",
            "Epoch 11/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3206 - accuracy: 0.8840 - val_loss: 0.3299 - val_accuracy: 0.8898\n",
            "Epoch 12/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3149 - accuracy: 0.8870 - val_loss: 0.3130 - val_accuracy: 0.8914\n",
            "Epoch 13/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3099 - accuracy: 0.8888 - val_loss: 0.3069 - val_accuracy: 0.8911\n",
            "Epoch 14/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3011 - accuracy: 0.8920 - val_loss: 0.3696 - val_accuracy: 0.8915\n",
            "Epoch 15/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2927 - accuracy: 0.8955 - val_loss: 0.3641 - val_accuracy: 0.8910\n",
            "Epoch 16/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2873 - accuracy: 0.8976 - val_loss: 0.2970 - val_accuracy: 0.8997\n",
            "Epoch 17/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2861 - accuracy: 0.8985 - val_loss: 0.2883 - val_accuracy: 0.8966\n",
            "Epoch 18/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2784 - accuracy: 0.9000 - val_loss: 0.3220 - val_accuracy: 0.8928\n",
            "Epoch 19/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2727 - accuracy: 0.9029 - val_loss: 0.3016 - val_accuracy: 0.8984\n",
            "Epoch 20/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2708 - accuracy: 0.9054 - val_loss: 0.3461 - val_accuracy: 0.8843\n",
            "Epoch 21/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2654 - accuracy: 0.9071 - val_loss: 0.3900 - val_accuracy: 0.8916\n",
            "Epoch 22/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2568 - accuracy: 0.9076 - val_loss: 0.3512 - val_accuracy: 0.8927\n",
            "Epoch 23/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2544 - accuracy: 0.9109 - val_loss: 0.3101 - val_accuracy: 0.8960\n",
            "Epoch 24/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2530 - accuracy: 0.9122 - val_loss: 0.3681 - val_accuracy: 0.8921\n",
            "Epoch 25/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2454 - accuracy: 0.9138 - val_loss: 0.3232 - val_accuracy: 0.8963\n",
            "Epoch 26/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2390 - accuracy: 0.9159 - val_loss: 0.3767 - val_accuracy: 0.8996\n",
            "Epoch 27/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2365 - accuracy: 0.9175 - val_loss: 0.3304 - val_accuracy: 0.8971\n",
            "Epoch 28/40\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2315 - accuracy: 0.9201 - val_loss: 0.4097 - val_accuracy: 0.8954\n",
            "Epoch 29/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2257 - accuracy: 0.9197 - val_loss: 0.3683 - val_accuracy: 0.8970\n",
            "Epoch 30/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2251 - accuracy: 0.9218 - val_loss: 0.3990 - val_accuracy: 0.8985\n",
            "Epoch 31/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2229 - accuracy: 0.9226 - val_loss: 0.4420 - val_accuracy: 0.8985\n",
            "Epoch 32/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2171 - accuracy: 0.9253 - val_loss: 0.3139 - val_accuracy: 0.8970\n",
            "Epoch 33/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2204 - accuracy: 0.9247 - val_loss: 0.3533 - val_accuracy: 0.8986\n",
            "Epoch 34/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2106 - accuracy: 0.9277 - val_loss: 0.3858 - val_accuracy: 0.8999\n",
            "Epoch 35/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2088 - accuracy: 0.9282 - val_loss: 0.3619 - val_accuracy: 0.8922\n",
            "Epoch 36/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2091 - accuracy: 0.9290 - val_loss: 0.4228 - val_accuracy: 0.8983\n",
            "Epoch 37/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2053 - accuracy: 0.9295 - val_loss: 0.4664 - val_accuracy: 0.8943\n",
            "Epoch 38/40\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2014 - accuracy: 0.9322 - val_loss: 0.4078 - val_accuracy: 0.8957\n",
            "Epoch 39/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2029 - accuracy: 0.9320 - val_loss: 0.3476 - val_accuracy: 0.9030\n",
            "Epoch 40/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1945 - accuracy: 0.9349 - val_loss: 0.4658 - val_accuracy: 0.8948\n",
            "10000/10000 [==============================] - 0s 31us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8-2d-GqtReE",
        "colab_type": "code",
        "outputId": "61e7d905-3f07-4e05-8507-2b1f34f60afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# savePath = '/content/drive/My Drive/4th Year/4YP/Fashion MNIST 60k/Results/' + folder + '/R(M,D+).csv'\n",
        "# pd.DataFrame(RawData_3).to_csv(savePath,header=None, index=None)\n",
        "print('R(M,D+):',(sum(Correctness_3) / 10000))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R(M,D+): 0.8939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AqDFBdNCtfcO",
        "outputId": "41249dfd-f7be-4185-9305-40737814db31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Test 4: R(M+,D+)\n",
        "# Full data import, learning and test of: D_train and D_test\n",
        "# loading modified Fashion MNIST dataset\n",
        "train = pd.read_csv(pathDplustrain,header=None)\n",
        "test = pd.read_csv(pathDplustest,header=None)\n",
        "(n_train,pixels) = np.shape(train)\n",
        "n_test = np.size(test,0)\n",
        "dim = int(np.sqrt(pixels-1))\n",
        "\n",
        "# Getting data in right form\n",
        "# input image dimensions\n",
        "img_rows, img_cols = dim, dim\n",
        "\n",
        "# Extracting data\n",
        "test_labels = test.iloc[:,0]\n",
        "test_values = test.iloc[:,1:]\n",
        "train_labels = train.iloc[:,0]\n",
        "train_values = train.iloc[:,1:]\n",
        "x_train = train_values.values.reshape(n_train,img_rows,img_cols,1)\n",
        "x_test = test_values.values.reshape(n_test,img_rows,img_cols,1)\n",
        "\n",
        "# print('x_train shape:', x_train.shape)\n",
        "# print(x_train.shape[0], 'train samples')\n",
        "# print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(train_labels, num_classes)\n",
        "y_test = keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Fit model and learn\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[tensorboard_callback])\n",
        "\n",
        "# Make predictions\n",
        "predictions_4 = model.predict(x_test, batch_size=batch_size,\n",
        "                            verbose=1,)\n",
        "# Forming into required raw data format\n",
        "predictions_4 = predictions_4.round(0)\n",
        "MLresults_4 = np.argmax(predictions_4,axis=1)\n",
        "\n",
        "Correctness_4 = np.zeros(len(predictions_4))\n",
        "for i in range(len(predictions_4)):\n",
        "  if np.array_equal(MLresults_4[i],test_labels[i]):\n",
        "    Correctness_4[i] = True\n",
        "  else:\n",
        "    Correctness_4[i] = False\n",
        "\n",
        "GroundTruth_4 = test_labels\n",
        "\n",
        "RawData_4 = np.zeros((n_test,5))\n",
        "RawData_4[:,1] = GroundTruth_4\n",
        "RawData_4[:,2] = MLresults_4\n",
        "RawData_4[:,4] = Correctness_4\n",
        "\n",
        "for i in range(len(GroundTruth_4)):\n",
        "  RawData_4[i,0] = i+1\n",
        "\n",
        "# Saving\n",
        "savePath = '/content/drive/My Drive/4th Year/4YP/Fashion MNIST 60k/Results/' + folder + '/R(M+,D+).csv'\n",
        "#pd.DataFrame(RawData_4).to_csv(savePath,header=None, index=None)\n",
        "\n",
        "# # Testing accuracy for interest\n",
        "# sum(Correctness_4) / 10000\n",
        "# #y_test = y_test.astype(np.float32)\n",
        "# score = model.evaluate(x_test, y_test, verbose=0)\n",
        "# print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2519 - accuracy: 0.9166 - val_loss: 0.3000 - val_accuracy: 0.8989\n",
            "Epoch 2/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2382 - accuracy: 0.9189 - val_loss: 0.3143 - val_accuracy: 0.8969\n",
            "Epoch 3/40\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2365 - accuracy: 0.9196 - val_loss: 0.3535 - val_accuracy: 0.8991\n",
            "Epoch 4/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2312 - accuracy: 0.9220 - val_loss: 0.3250 - val_accuracy: 0.8970\n",
            "Epoch 5/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2293 - accuracy: 0.9224 - val_loss: 0.3144 - val_accuracy: 0.8921\n",
            "Epoch 6/40\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2243 - accuracy: 0.9231 - val_loss: 0.3218 - val_accuracy: 0.8949\n",
            "Epoch 7/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2222 - accuracy: 0.9241 - val_loss: 0.3424 - val_accuracy: 0.8961\n",
            "Epoch 8/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2171 - accuracy: 0.9258 - val_loss: 0.3121 - val_accuracy: 0.8948\n",
            "Epoch 9/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2156 - accuracy: 0.9265 - val_loss: 0.4612 - val_accuracy: 0.8975\n",
            "Epoch 10/40\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2169 - accuracy: 0.9261 - val_loss: 0.3461 - val_accuracy: 0.9000\n",
            "Epoch 11/40\n",
            "60000/60000 [==============================] - 5s 87us/sample - loss: 0.2153 - accuracy: 0.9277 - val_loss: 0.3749 - val_accuracy: 0.8965\n",
            "Epoch 12/40\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2116 - accuracy: 0.9288 - val_loss: 0.5000 - val_accuracy: 0.8997\n",
            "Epoch 13/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2148 - accuracy: 0.9288 - val_loss: 0.3524 - val_accuracy: 0.8968\n",
            "Epoch 14/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2097 - accuracy: 0.9303 - val_loss: 0.3401 - val_accuracy: 0.8970\n",
            "Epoch 15/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2074 - accuracy: 0.9294 - val_loss: 0.4191 - val_accuracy: 0.8967\n",
            "Epoch 16/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2093 - accuracy: 0.9311 - val_loss: 0.3825 - val_accuracy: 0.8972\n",
            "Epoch 17/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2046 - accuracy: 0.9323 - val_loss: 0.3403 - val_accuracy: 0.8942\n",
            "Epoch 18/40\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2072 - accuracy: 0.9307 - val_loss: 0.3086 - val_accuracy: 0.8949\n",
            "Epoch 19/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2052 - accuracy: 0.9305 - val_loss: 0.3390 - val_accuracy: 0.8934\n",
            "Epoch 20/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2013 - accuracy: 0.9329 - val_loss: 0.4169 - val_accuracy: 0.8977\n",
            "Epoch 21/40\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2059 - accuracy: 0.9322 - val_loss: 0.3814 - val_accuracy: 0.8968\n",
            "Epoch 22/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2005 - accuracy: 0.9329 - val_loss: 0.3684 - val_accuracy: 0.8965\n",
            "Epoch 23/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2021 - accuracy: 0.9324 - val_loss: 0.3429 - val_accuracy: 0.8939\n",
            "Epoch 24/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2032 - accuracy: 0.9333 - val_loss: 0.4503 - val_accuracy: 0.8971\n",
            "Epoch 25/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2036 - accuracy: 0.9329 - val_loss: 0.3432 - val_accuracy: 0.8939\n",
            "Epoch 26/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1981 - accuracy: 0.9340 - val_loss: 0.4062 - val_accuracy: 0.8956\n",
            "Epoch 27/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1942 - accuracy: 0.9362 - val_loss: 0.4197 - val_accuracy: 0.9008\n",
            "Epoch 28/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1982 - accuracy: 0.9355 - val_loss: 0.4101 - val_accuracy: 0.8959\n",
            "Epoch 29/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1976 - accuracy: 0.9360 - val_loss: 0.3521 - val_accuracy: 0.8938\n",
            "Epoch 30/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1993 - accuracy: 0.9348 - val_loss: 0.3418 - val_accuracy: 0.8977\n",
            "Epoch 31/40\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1984 - accuracy: 0.9346 - val_loss: 0.3618 - val_accuracy: 0.8976\n",
            "Epoch 32/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2001 - accuracy: 0.9351 - val_loss: 0.3964 - val_accuracy: 0.9029\n",
            "Epoch 33/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1990 - accuracy: 0.9349 - val_loss: 0.3828 - val_accuracy: 0.8976\n",
            "Epoch 34/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1972 - accuracy: 0.9358 - val_loss: 0.4579 - val_accuracy: 0.8964\n",
            "Epoch 35/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1912 - accuracy: 0.9372 - val_loss: 0.3875 - val_accuracy: 0.8986\n",
            "Epoch 36/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1913 - accuracy: 0.9381 - val_loss: 0.3428 - val_accuracy: 0.8922\n",
            "Epoch 37/40\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2001 - accuracy: 0.9348 - val_loss: 0.3876 - val_accuracy: 0.9008\n",
            "Epoch 38/40\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1976 - accuracy: 0.9351 - val_loss: 0.4310 - val_accuracy: 0.8939\n",
            "Epoch 39/40\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1888 - accuracy: 0.9395 - val_loss: 0.3598 - val_accuracy: 0.8988\n",
            "Epoch 40/40\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1934 - accuracy: 0.9370 - val_loss: 0.3845 - val_accuracy: 0.8963\n",
            "10000/10000 [==============================] - 0s 26us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y_9jc65LKaW",
        "colab_type": "code",
        "outputId": "64e13b86-53ac-4731-c00b-c1a39f7e60ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "savePath = '/content/drive/My Drive/4th Year/4YP/Fashion MNIST 60k/Results/' + folder + '/R(M+,D+).csv'\n",
        "pd.DataFrame(RawData_4).to_csv(savePath,header=None, index=None)\n",
        "print('R(M+,D+):',(sum(Correctness_4) / 10000))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R(M+,D+): 0.8903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaKsrsppTptl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing accuracy for interest\n",
        "print(folder)\n",
        "print('Accuracies for each test:')\n",
        "print('R(M,D):',(sum(Correctness_1) / 10000))\n",
        "print('R(M+,D):',(sum(Correctness_2) / 10000))\n",
        "print('R(M,D+):',(sum(Correctness_3) / 10000))\n",
        "print('R(M+,D+):',(sum(Correctness_4) / 10000))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FV_5MAlupMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill 725\n",
        "%tensorboard --logdir logs  # start Tensorboard\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q-VLGiRckTvF",
        "outputId": "11bf9a8c-80f2-4ddc-fa7c-c91d9523be3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# Sets paths for train/test D/D+\n",
        "folder = 'Rotating'\n",
        "path = '/content/drive/My Drive/4th Year/4YP/Fashion MNIST 60k/Results/'\n",
        "pathDM  = path[:74] + folder  + '/R(M,D).csv'\n",
        "pathDplusM  = path[:74] + folder  + '/R(M,D+).csv'\n",
        "pathDMplus  = path[:74] + folder  + '/R(M+,D).csv'\n",
        "pathDplusMplus  = path[:74] + folder  + '/R(M+,D+).csv'\n",
        "\n",
        "DM = pd.read_csv(pathDM,header=None).to_numpy()\n",
        "DplusM = pd.read_csv(pathDplusM,header=None).to_numpy()\n",
        "DMplus = pd.read_csv(pathDMplus,header=None).to_numpy()\n",
        "DplusMplus = pd.read_csv(pathDplusMplus,header=None).to_numpy()\n",
        "\n",
        "Correctness_1 = DM[:,4].sum() / 10000\n",
        "Correctness_2 = DMplus[:,4].sum() / 10000\n",
        "Correctness_3 = DplusM[:,4].sum() / 10000\n",
        "Correctness_4 = DplusMplus[:,4].sum() / 10000\n",
        "\n",
        "print(folder)\n",
        "print('Accuracies for each test:')\n",
        "print('R(M,D):',Correctness_1)\n",
        "print('R(M+,D):',Correctness_2)\n",
        "print('R(M,D+):',Correctness_3)\n",
        "print('R(M+,D+):',Correctness_4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rotating\n",
            "Accuracies for each test:\n",
            "R(M,D): 0.6875\n",
            "R(M+,D): 0.1737\n",
            "R(M,D+): 0.2613\n",
            "R(M+,D+): 0.8782\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}