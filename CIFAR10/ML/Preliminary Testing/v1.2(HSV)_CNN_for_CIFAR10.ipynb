{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "name": "v1.2(HSV)_CNN_for_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walexand3r/4YP/blob/master/CIFAR10/ML/Preliminary%20Testing/v1.2(HSV)_CNN_for_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgeRXODCpXnN",
        "colab_type": "text"
      },
      "source": [
        "Reproducing Jack Pegg's work, using CNN on CIFAR-10 dataset on HSV Values. \n",
        "\n",
        "Initial testing of HSV/RGB only\n",
        "\n",
        "Model Version 1.2\n",
        "\n",
        "Added: \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcOpH2s7jxyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# This block imports relevant packages and sets intial seed to ensure reproducability\n",
        "# Seed value\n",
        "seed_value= 0\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os, datetime\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(seed_value)\n",
        "# for later versions: tf.random.set_random_seed(seed_value)\n",
        "\n",
        "# 5. Configure a new global `tensorflow` session\n",
        "import tensorflow.keras as keras\n",
        "# from tensorflow.keras import backend as K\n",
        "# session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "# sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "# K.set_session(sess)\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten,  Reshape, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, LeakyReLU, Softmax\n",
        "from tensorflow import math\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.color import rgb2hsv, hsv2rgb\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "%load_ext tensorboard\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7hNI5LLvrTqR",
        "colab": {}
      },
      "source": [
        "# Mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zuFOTq9KixG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting paths\n",
        "# Import data path\n",
        "folder = 'HSV'\n",
        "path = '/content/drive/My Drive/4th Year/4YP/CIFAR10/Processed Datasets/'\n",
        "pathTrain  = path[:74] + folder + '/train_hsv.csv'\n",
        "pathTest = path[:74] + folder + '/test_hsv.csv'\n",
        "\n",
        "# Sets results rath\n",
        "folder = 'HSV'\n",
        "savePath = '/content/drive/My Drive/4th Year/4YP/CIFAR-10/Results/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYod8Lp3KZpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load CIFAR_10 data\n",
        "train = pd.read_csv(pathTrain,header=None)\n",
        "test = pd.read_csv(pathTest,header=None)\n",
        "\n",
        "(n_train,row_length) = np.shape(train)\n",
        "pixels = (row_length - 1) / 3\n",
        "n_test = np.size(test,0)\n",
        "dim = int(np.sqrt(pixels))\n",
        "num_classes = 10\n",
        "\n",
        "# Getting data in right form\n",
        "# input image dimensions\n",
        "img_rows, img_cols = dim, dim\n",
        "\n",
        "# Extracting data\n",
        "test_labels = test.iloc[:,0]\n",
        "test_values = test.iloc[:,1:] \n",
        "train_labels = train.iloc[:,0]\n",
        "train_values = train.iloc[:,1:] \n",
        "x_train = train_values.values.reshape(n_train,img_rows,img_cols,3)\n",
        "x_test = test_values.values.reshape(n_test,img_rows,img_cols,3)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(train_labels, num_classes)\n",
        "y_test = keras.utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MuaPOiAXxnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 50\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = Conv2D(64, kernel_size = (3,3), padding = 'same')(inputs)\n",
        "x = LeakyReLU(alpha = 0.3)(x)\n",
        "\n",
        "x = Conv2D(64, kernel_size=(3, 3), padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.3)(x)\n",
        "x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "x = Conv2D(128, kernel_size=(3, 3), padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.3)(x)\n",
        "\n",
        "x = Conv2D(128, kernel_size=(3, 3), padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.3)(x)\n",
        "x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "x = Conv2D(256, kernel_size=(3, 3), padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.3)(x)\n",
        "\n",
        "x = Conv2D(256, kernel_size=(1, 1), padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.3)(x)\n",
        "x = Dropout(rate = 0.5)(x)\n",
        "\n",
        "x = Conv2D(10, kernel_size=(3, 3), padding = 'same')(x)\n",
        "x = LeakyReLU(alpha = 0.3)(x)\n",
        "x = tf.reduce_mean(x,(1,2))\n",
        "outputs = Softmax()(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='cifar_model')\n",
        "\n",
        "model.compile(loss = keras.losses.categorical_crossentropy,\n",
        "              optimizer = keras.optimizers.Adam(learning_rate = 0.001, beta_1 = 0.98),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#model.summary()\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKpe3LyYd9FL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_split = 0.02)\n",
        "\n",
        "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Test loss:', test_scores[0])\n",
        "print('Test accuracy:', test_scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FV_5MAlupMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill 725\n",
        "%tensorboard --logdir logs  # start Tensorboard\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}